---
layout: post
title: 인공지능 & Pytorch
date: 2021-11-23 21:24 
last_modified_at: 2021-11-23 21:24
tags: [인공지능,pytorch]
toc:  true
---

* #### python을 기본적으로 사용합니다  
* #### Gpu을 사용하기 위하여 Goole에서 이용할 수 있는 Colab을 이용해서 실행

## 인공지능을 위한 pytorch 배우기 

### __1.Tensor(텐서)__ : pytorch 의 기본단위이며 __GPU 계산__ 을 할 수 있게 해준다 numpy와 상당히 유사하다.
#### __1.1 Tensor 생성__ : 라이브러리 불러오기

```python
import torch # Pytorch를 사용하기 위한 기본 라이브러리
import numpy as np #Numpy를 사용하기 위한 기본 라이브러리 np로 줄여서 사용

X = torch.empty(5,4) # 5X4 행렬 생성
print(X)
X = torch.ones(3,3) # 원소가 모두 1인 3X3 행렬 생성
print(X)
X = torch.zeros(2) # 원소가 모두 0인 2행 Vector
print(X)
X = torch.rand(5,6) # 표준정규분포를 따르는 무작위 원소의 5X6 행렬 생성
print(X) 
```
#### 1.2 List, Numpy 배열을 Tensor로 만들기

```python
리스트 = [3,4] # list 생성
넘파이 = np.array([4,50,7]) # numpy 배열 생성
torch.tensor(리스트) # List → Tensor
torch.tensor(넘파이) # Numpy → Tensor
```

#### 1.3 Tensor의 크기와 타입 확인하기
```python
X.size()  #.size()는 Tensor의 크기를 확인할 수 있다.
type(X) # type은 Python에서 사용되는 모든 것들을 종류로 보여준다.
```

#### 1.4 Tensor의 연산
```python
# 크기가 같아야 한다.
X = torch.rand(2,2) # 2X2 랜덤 행렬
Y = torch.rand(2,2) # 2X2 랜덤 행렬
print("X:",X)
print("Y:",Y)
X+Y # 첫번째 표현
torch.add(X,Y) # 두번째 표현
Y.add_(X) #세번째 표현이며 Y = X+Y 와 같은의미이며 inplace 방식이라고 한다.
print("기존 Y:",Y)  # 기존  Y값
Y.add_(X)  # Y = X+Y 연산
print("inplace Y:",Y)  # 대체된 Y값
```
#### 1.5 Tensor의 크기 변환

```python
# view 함수를 사용하여 크기를 변환

X = torch.rand(8,8) # 8X8랜덤 행렬
print("size of X:",X.size()) # size 확인 
A = X.view(64) #  8X8 행렬을 64개의 Vector로 바꿔준다 
print("size of A:",A.size()) # size 확인
B = X.view(-1,4,4) 
''' -1은 다른 인자를 우선으로 크기로 맞춘 뒤 남는 부분을 자동으로 맞춰달라는 의미 
→ 8X8 행렬을 -1X4X4로 표현하려면 -1자리에는 4가 들어가서 4X4X4 행렬이 되어야 한다. 따라서 -1자리에는 4가 자동으로 맞춰짐
'''
print("size of B:",B.size()) #size확인
```
#### 1.6 Tensor를 Numpy 만들기 
```python
X = torch.rand(4,4) # 4X4 랜덤 행렬 
Y = X.numpy() # Tensor → Numpy
print("Y :",Y) # Y값 확인
type(Y) # Y의 타입 확인
```

### 1.7 단일 Tensor에서 값 추출

```python
X = torch.ones(1) # 원소가 1인 Vecotr하나 생성
print("X:",X)
print(X.item()) # 원소가 하나일 때만 사용가능하며 tensor안에 하나의 스칼라 값을 가져온다. 텐서(행렬)가 아님
#  loss 값을 저장하기 위함
```